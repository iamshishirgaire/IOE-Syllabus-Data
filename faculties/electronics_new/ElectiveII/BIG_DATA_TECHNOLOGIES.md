# Syllabus: Big Data Technologies (CT 765 07)

## Course Objectives

The growth of information systems has generated large amounts of data that don't fit the traditional definition of data. This creates new opportunities but also presents significant challenges, particularly in storing, analyzing, and searching such vast datasets. Fortunately, numerous technologies have emerged to address these challenges. This course introduces this landscape along with the relevant technologies and how they solve these problems.

The course aims to:

* Introduce students to the current state of big data and its various facets.
* Familiarize students with key technologies in the field.
* Equip students with the knowledge to use these technologies to solve big data problems in different domains.

## Course Outline

1. **Introduction to Big Data (7 hours)**
    * Big Data Overview
    * Background of Data Analytics
    * Role of Distributed Systems in Big Data
    * Role of Data Scientists
    * Current Trends in Big Data Analytics

2. **Google File System (7 hours)**
    * Architecture
    * Availability
    * Fault Tolerance
    * Optimization for Large-Scale Data

3. **Map-Reduce Framework (10 hours)**
    * Basics of Functional Programming
    * Fundamentals of Functional Programming
    * Modeling Real-World Problems in a Functional Style
    * Map Reduce Fundamentals
    * Data Flow (Architecture)
    * Real-World Problems
    * Scalability Goals
    * Fault Tolerance
    * Optimization and Data Locality
    * Parallel Efficiency of Map-Reduce

4. **NoSQL (6 hours)**
    * Structured and Unstructured Data
    * Taxonomy of NoSQL Implementations
    * Discussion of the Basic Architecture of Hbase, Cassandra, and MongoDb

5. **Searching and Indexing Big Data (7 hours)**
    * Full Text Indexing and Searching
    * Indexing with Lucene
    * Distributed Searching with Elasticsearch

6. **Case Study: Hadoop (8 hours)**
    * Introduction to the Hadoop Environment
    * Data Flow
    * Hadoop I/O
    * Query Languages for Hadoop
    * Hadoop and Amazon Cloud

## Practical

Students will have the opportunity to work with big data technologies using various dummy and real-world problems that cover all the aspects discussed in the course. This hands-on experience will provide practical insights into the challenges faced and how to tackle them using the tools learned in the course.

* **HDFS:** Setup a single-node to multi-node HDFS cluster, perform basic file system operations using commands, monitor cluster performance.
* **Map-Reduce:** Write various MR programs dealing with different aspects of MapReduce as studied in the course.
* **Hbase:** Setup Hbase in single-node and distributed mode, write programs to write data into Hbase and query it.
* **Elastic Search:** Setup Elasticsearch in single-node and distributed mode, define templates, write data, and query it.
* **Final Assignment:** A final assignment covering all aspects studied in order to demonstrate the student's problem-solving capabilities in a big data scenario.

## References

1. Jeffrey Dean, Sanjay Ghemawat: *MapReduce: Simplified Data Processing on Large Clusters*
2. Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung: *The Google File System*
3. [http://wiki.apache.org/hadoop/](http://wiki.apache.org/hadoop/)

## Evaluation Scheme

The questions will cover all chapters of the syllabus. The evaluation scheme is as follows:

| Chapters | Hours | Marks Distribution\* |
|---|---|---|
| 1 | 7 | 12 |
| 2 | 7 | 13 |
| 3 | 10 | 18 |
| 4 | 6 | 11 |
| 5 | 7 | 13 |
| 6 | 8 | 13 |
| **Total** | **45** | **80** |

\*There could be a minor deviation in marks distribution.

## Copyright

Copyright Â© 2021 
